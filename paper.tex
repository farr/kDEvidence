\documentclass[prd,preprint]{revtex4}

\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{color}

\newcommand{\vtheta}{\vec{\theta}}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bel}[1]{\begin{equation}\label{#1}}
\newcommand{\ba}{\begin{eqnarray}}
\newcommand{\ea}{\end{eqnarray}}
\newcommand{\bal}[1]{\begin{eqnarray}\label{#1}}

\def\ilya{\textcolor{red}}
\def\will{\textcolor{blue}}


\bibliographystyle{h-physrev}

\begin{document}
\title{An Efficient Interpolation Technique for Jump Proposals in
  Reversible-Jump Markov Chain Monte Carlo Calculations}

\date{\today}

\author{Will M. Farr}
\email{w-farr@northwestern.edu}

\affiliation{Northwestern University Center for Interdisciplinary
  Research and Education in Astrophysics}

\author{Ilya Mandel}
\email{ilyamandel@chgk.info}

\affiliation{MIT Kavli Institute; and University of Birmingham, UK}

\begin{abstract}
\ilya{Add physics/astro motivation}
  Reversible-jump Markov chain monte carlo (RJMCMC) is an extremely
  powerful technique for performing Bayesian model selection, but it
  suffers from a fundamental difficulty: it requires jumps between
  model parameter spaces, but cannot retain a memory of the favored
  locations in more than one parameter space at a time.  Thus, a naive
  jump between parameter spaces is unlikely to be accepted in the MCMC
  algorithm and convergence is correspondingly slow.  Here we
  demonstrate an interpolation technique that uses samples from
  single-model MCMCs to propose inter-model jumps from an
  approximation to the single-model posterior of the target parameter
  space.  The interpolation technique, based on a kD-tree
  data structure, is adaptive and efficient in arbitrary dimensions.
  We show that our technique leads to dramatically improved convergence
  over naive jumps in an RJMCMC, and compare it to other proposals in
  the literature to improve the convergence of RJMCMCs.  We also
  discuss the use of the same interpolation technique in two other
  contexts: as a convergence test for a single-model MCMC and as a way
  to construct efficient ``global'' proposal distributions for
  single-model MCMCs without prior knowledge of the structure of the
  posterior distribution.
\end{abstract}

\maketitle

\section{Introduction}

\section{Reversible Jump MCMC}

Reversible jump MCMC (RJMCMC) \cite{Green1995} is a technique for Bayesian model comparison.  Below, we give a very brief introduction to Bayesian analysis; describe a standard MCMC; and introduce RJMCMC.

\subsection{Bayesian analysis}

Consider an observed data set $d$ and a set of competing models for the data, indexed by an integer $i$: $\{M_i | i = 1, 2, \ldots \}$.  Each model has some continuous parameters, $\vtheta_i$; given the model and its parameters, we can make a prediction about the likelihood of observing
the experimental data: $L(d|\vtheta_i, M_i)$.  Within the framework of each model, Bayes' rule gives us a way to compute the posterior probability distribution function (PDF) for the model
parameters implied by the data:
\begin{equation}
  p(\vtheta_i | d, M_i) = \frac{L(d|\vtheta_i, M_i) p(\vtheta_i|M_i)}{p(d|M_i)},
\end{equation}
where $p(M_i, \vtheta_i |d)$ is the posterior distribution for the
model parameters $\vtheta_i$ implied by the data in the context of
model $M_i$, $p(\vtheta_i|M_i)$ is the prior
probability of the model parameters that 
represents our beliefs before accumulating any of the data $d$, and
$p(d)$ is an overall normalizing constant that ensures that $p(\vtheta_i|d,M_i)$ is properly normalized as a probability distribution on
the $\vtheta_i$.  This implies that the evidence is equal to
\bel{evidence}
  p(d|M_i) = \int_{V_i} d\vtheta_i L(d|\vtheta_i, M_i) p(\vtheta_i|M_i),
\end{equation}
where $V_i$ is the parameter space volume in model $M_i$.  We are interested in the evidence for model $M_i$ given the data, $p(M_i|d)$, which is again given by Bayes' rule as
\begin{equation}
p(M_i|d) = \frac{p(d|M_i) p(M_i)}{p(d)},
\end{equation},
where $p(M_i)$ is our a priori belief in model $M_i$ and $p(d)$ is a normalizing constant, 
\be
p(d)=\sum_i p(d|M_i) p(M_i).
\ee

When selecting among alternative models, we are interested in finding the model with the highest evidence $p(M_i|d)$.  However, attempts to directly compute the evidence by performing the integration in Eq.~(\ref{bel}) are generally very difficult in a multi-dimensional, multi-modal parameter space when the likelihood has to be evaluated numerically.  In particular, a grid-based integral quickly becomes computationally unfeasible as the dimensionality of $\vtheta$ exceeds a few.  The parameter space must typically be explored in a stochastic manner before the evidence integral can be computed.  Although several stochastic parameter-exploration techniques are focused directly on evidence computation (e.g., nested sampling and MultiNest \ilya {Add references}), we frequently want to compute the posterior PDFs within each model along with the evidences for the various models, and the Markov chain Monte Carlo is one of the most widely used tools for this purpose. 

\subsection{MCMC}

A Markov chain Monte Carlo produces a set of samples $\{ \vtheta^(i) \, | \, i = 1, \ldots \}$ from the model parameter space that are sampled according to the posterior, meaning that, in the limit that the chain length tends to infinity, the relative frequency with which a given set of parameter appears in the chain is proportional to the desired posterior, $p(\vtheta|d,M)$.  Therefore, the output of an MCMC can be directly interpreted as the posterior PDF over the full parameter space, while PDFs for individual parameters can be obtained through trivially marginalizing over the uninteresting parameters, simply by considering the distribution of the parameter of interest in the MCMC samples.

A Markov chain has the property that the probability distribution of the next state can depend only on the current state, not on the past history:
\be
p(\vtheta^(i+1))=\int_{V} d\vtheta^{i} p(\vtheta^{i} \to \vtheta^{i+1}) p(\vtheta^{i+1}),
\ee
where $p(\vtheta^{i} \to \vtheta^{i+1})$ depends only on $\vtheta^{i}$ and $\vtheta^{i+1}$. 
An additional requirement for an MCMC arises from the fact that the desired distribution is the equilibrium distribution.  In other words, if we assume that state $(i)$ of the chain is sampled from the desired PDF, $p(\vtheta^{i})=p(\vtheta|d,M)$ , then the next state $(i+1)$ must be sampled from the PDF as well, so that $p(\vtheta^{i+1})=p(\vtheta|d,M)$.  

One way to produce such a sequence of samples is via the Metropolis-Hastings algorithm, first proposed by Metropolis et al.~in 1953 \cite{Metropolis:1953}, and later generalized by Hastings:
\begin{enumerate}
  \item Given a current state $\vtheta^(i)$, propose the next state $\vtheta^p$ by drawing from a jump proposal distribution with probability $Q(\vtheta^(i) \to \vtheta^p)$.  
  \item Compute the probability of accepting the proposed jump as
\be
p_{\textnormal{accept}}  \equiv \min\Bigl(1,  frac{p(\vtheta^p|d)}{p(\vtheta^(i)|d)} \frac{Q(\vtheta^p \to
        \vtheta^(i))}{Q(\vtheta^(i) \to \vtheta^p)} \Bigr).
\ee
\item Pick a uniform random number $\alpha \in [0,1]$.  If $\alpha<  p_{\textnormal{accept}}$, accept the proposed jump, setting $\vtheta^(i+1)=\vtheta^p$.  Otherwise, reject the jump, and remain at the same location in parameter space for the next step, $\vtheta^(i+1)=\vtheta^(i)$.
 \end{itemize}
 
This jump proposal distribution $Q(\vtheta^(i) \to \vtheta^p)$ can depend on the parameters of the current state $\vtheta^(i)$, but not on the past history.  It must also allow any state within the allowed prior volume to be reachable by the MCMC.  Beyond these conditions, there is obviously a great deal of freedom in choosing the jump proposal distribution.  This is the most important choice in the MCMC, as it determines the sampling efficiency of the algorithm, i.e., the necessary length of the chain before it converges to the posterior PDF.  Creating an efficient jump proposal distribution requires an understanding of the structure of the parameter space which may not be available until the PDFs are found, creating a Catch-22; one possibility for resolving this infinite loop is described in Section \ref{sec:examples}.

It should be noted that although an MCMC who jump acceptance criterium obeys detailed balance (as the Metropolis-Hastings algorithm does) must eventually converge to the desired distribution, there is no way to guarantee convergence in a fixed number of steps or to test whether a chain has converged in a foolproof manner.  For example, MCMC chains can get stuck on local maxima, and if the autocorrelation length of the chain represents a substantial fraction of the total number of samples, the effective sample size may be too small to accurately represent the relative sizes of the modes in the PDF (however, see Section \ref{sec:examples} for one intriguing suggestion for remedying this issue).   

Finally, we note that, in practice, the randomly chosen initial starting point of the MCMC may be in a particularly unlikely location in the parameter space.  Because jumps are frequently local, we will generally want to ignore the first few autocorrelation lengths worth of points in a finite-size chain to avoid biases in the recovered posterior PDF due to the choice of the initial location.  The points thus discarded are referred to as "burn-in" points.

\subsection{RJMCMC}

The samples produced during a Markov Chain Monte Carlo can be used to directly perform a Monte Carlo evidence integral.  This results in a harmonic mean estimator for the evidence, which suffers from a large variance and a possible bias.  Additional techniques for the direct integration of evidence are described in 

An alternative approach to model selection  models


Consider the problem of model selection among a set of models, and the
``super-model'' that encompasses all the models under consideration.
The parameter space of the super-model consists of a discrete
parameter that identifies the choice of model, $M_i$, and the
continuous parameters appropriate for this model, $\vtheta_i$.  We
denote a point in the super-model parameter space by $\{M_i,
\vtheta_i\}$; each such point is a statement that, e.g., ``the
underlying mass distribution for black holes in the galaxy is a
Gaussian, with parameters $\mu$ and $\sigma$,'' or ``the underlying
mass distribution for black holes in the galaxy is a triple-bin
histogram with parameters $w_1$, $w_2$, $w_3$, and $w_4$,'' or ....
To compare models, we are interested in the quantity (see Equation
\eqref{eq:model-posterior-def})
\begin{equation}
  p(M_i|d) = \int d\vtheta_i p(M_i, \vtheta_i|d).
\end{equation}
If we perform an MCMC in the super-model parameter space, then we
obtain a chain of samples $\{M_i, \vtheta_i \, | \, i = 1, \ldots\}$
distributed in parameter space with density $p(M_i,\vtheta_i|d)
d\vtheta_i$ and we can estimate the integral as
\begin{equation}
    p(M_i|d) = \int d\vtheta_i p(M_i, \vtheta_i|d) \approx \frac{N_i}{N},
\end{equation}
where $N_i$ is the number of samples in the chain lying in the
parameter space of model $M_i$ and $N$ is the total number of samples
in the chain.  The fraction of samples lying in the parameter space of
model $M_i$ gives the probability of that model relative to the other
models under consideration.

To perform the MCMC in the super-model parameter space, we must
propose jumps not only between points in a particular model's
parameter space, but also between the parameter spaces of different
models.  For this MCMC to be efficient, proposed jumps into a model
from another should favor regions with large posterior; when the
posterior is highly-peaked in a small region of parameter space,
proposed jumps outside this region are unlikely to be accepted, and
the reversible-jump MCMC samples will require a very long chain to
properly sample the ``super-model'' posterior.

We can exploit the information we have from single-model MCMCs to
generate efficient jump proposal distributions for our reversible jump
MCMC.  We would like to propose jumps that roughly follow the
distribution of samples in the single-model MCMCs. 





\section{kD Trees and Interpolation}

Mention example of bricks from \cite{Littenberg2009}.

\section{RJMCMC Efficiency}

\section{Examples and other uses} \label{sec:examples}

BH mass paper [still not sure how to present this without repetition...  ]  

GW parameter estimation


\section{Conclusion/Discussion}

...

\subsection{Other Uses}
The efficient interpolation of a PDF via a kD-tree described in this paper can be extremely useful in other contexts, beyond a reversible-jump MCMC.  We suggest two examples below: generating efficient jump proposal distributions and convergence tests?

...

Mention nested sampling?

\nocite{Littenberg2009}

\bibliography{paper}

\end{document}