\documentclass[prd,preprint]{revtex4}

\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{color}

\newcommand{\vtheta}{\vec{\theta}}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bel}[1]{\begin{equation}\label{#1}}
\newcommand{\ba}{\begin{eqnarray}}
\newcommand{\ea}{\end{eqnarray}}
\newcommand{\bal}[1]{\begin{eqnarray}\label{#1}}

\newcommand{\ilya}[1]{{\color{red} \bf Ilya: #1}}
\newcommand{\will}[1]{{\color{blue} \bf Will: #1}}


\bibliographystyle{h-physrev}

\begin{document}
\title{An Efficient Interpolation Technique for Jump Proposals in
  Reversible-Jump Markov Chain Monte Carlo Calculations}

\date{\today}

\author{Will M. Farr}
\email{w-farr@northwestern.edu}

\affiliation{Northwestern University Center for Interdisciplinary
  Research and Education in Astrophysics}

\author{Ilya Mandel}
\email{ilyamandel@chgk.info}

\affiliation{MIT Kavli Institute; and University of Birmingham, UK}

\begin{abstract}
\ilya{Add physics/astro motivation}
  Reversible-jump Markov chain monte carlo (RJMCMC) is an extremely
  powerful technique for performing Bayesian model selection, but it
  suffers from a fundamental difficulty: it requires jumps between
  model parameter spaces, but cannot retain a memory of the favored
  locations in more than one parameter space at a time.  Thus, a naive
  jump between parameter spaces is unlikely to be accepted in the MCMC
  algorithm and convergence is correspondingly slow.  Here we
  demonstrate an interpolation technique that uses samples from
  single-model MCMCs to propose inter-model jumps from an
  approximation to the single-model posterior of the target parameter
  space.  The interpolation technique, based on a kD-tree
  data structure, is adaptive and efficient in arbitrary dimensions.
  We show that our technique leads to dramatically improved convergence
  over naive jumps in an RJMCMC, and compare it to other proposals in
  the literature to improve the convergence of RJMCMCs.  We also
  discuss the use of the same interpolation technique in two other
  contexts: as a convergence test for a single-model MCMC and as a way
  to construct efficient ``global'' proposal distributions for
  single-model MCMCs without prior knowledge of the structure of the
  posterior distribution.
\end{abstract}

\maketitle

\section{Introduction}

\section{Reversible Jump MCMC}

Reversible jump Markov chain Monte Carlo (RJMCMC) \cite{Green1995} is a technique for Bayesian model comparison.  Below, we give a very brief introduction to Bayesian analysis; describe a standard MCMC; and introduce RJMCMC.

\subsection{Bayesian analysis}

Consider an observed data set $d$ and a set of competing models for the data, indexed by an integer $i$: $\{M_i | i = 1, 2, \ldots \}$.  Each model has some continuous parameters, $\vtheta_i$; given the model and its parameters, we can make a prediction about the likelihood of observing
the experimental data: $L(d|\vtheta_i, M_i)$.  Within the framework of each model, Bayes' rule gives us a way to compute the posterior probability distribution function (PDF) for the model
parameters implied by the data:
\begin{equation}
  p(\vtheta_i | d, M_i) = \frac{L(d|\vtheta_i, M_i) p(\vtheta_i|M_i)}{p(d|M_i)},
\end{equation}
where $p(M_i, \vtheta_i |d)$ is the posterior distribution for the
model parameters $\vtheta_i$ implied by the data in the context of
model $M_i$, $p(\vtheta_i|M_i)$ is the prior
probability of the model parameters that 
represents our beliefs before accumulating any of the data $d$, and
$p(d)$ is an overall normalizing constant that ensures that $p(\vtheta_i|d,M_i)$ is properly normalized as a probability distribution on
the $\vtheta_i$.  This implies that the evidence is equal to
\bel{evidence}
  p(d|M_i) = \int_{V_i} d\vtheta_i L(d|\vtheta_i, M_i) p(\vtheta_i|M_i),
\end{equation}
where $V_i$ is the parameter space volume in model $M_i$.  We are interested in the evidence for model $M_i$ given the data, $p(M_i|d)$, which is again given by Bayes' rule as
\begin{equation}
p(M_i|d) = \frac{p(d|M_i) p(M_i)}{p(d)},
\end{equation}
where $p(M_i)$ is our a priori belief in model $M_i$ and $p(d)$ is a normalizing constant, 
\be
p(d)=\sum_i p(d|M_i) p(M_i).
\ee

When selecting among alternative models, we are interested in finding the model with the highest evidence $p(M_i|d)$.  However, attempts to directly compute the evidence by performing the integration in Eq.~(\ref{bel}) are generally very difficult in a multi-dimensional, multi-modal parameter space when the likelihood has to be evaluated numerically.  In particular, a grid-based integral quickly becomes computationally unfeasible as the dimensionality of $\vtheta$ exceeds a few.  The parameter space must typically be explored in a stochastic manner before the evidence integral can be computed.  Although several stochastic parameter-exploration techniques are focused directly on evidence computation (e.g., nested sampling and MultiNest \ilya {Add references}), we frequently want to compute the posterior PDFs within each model along with the evidences for the various models, and the Markov chain Monte Carlo is one of the most widely used tools for this purpose. 

\subsection{MCMC}

A Markov chain Monte Carlo produces a set of samples $\{ \vtheta^{(i)} \, | \, i = 1, \ldots \}$ from the model parameter space that are sampled according to the posterior, meaning that, in the limit that the chain length tends to infinity, the relative frequency with which a given set of parameter appears in the chain is proportional to the desired posterior, $p(\vtheta|d,M)$.  Therefore, the output of an MCMC can be directly interpreted as the posterior PDF over the full parameter space, while PDFs for individual parameters can be obtained through trivially marginalizing over the uninteresting parameters, simply by considering the distribution of the parameter of interest in the MCMC samples.

A Markov chain has the property that the probability distribution of the next state can depend only on the current state, not on the past history:
\be
p(\vtheta^(i+1))=\int_{V} d\vtheta^{i} p(\vtheta^{(i)} \to \vtheta^{(i+1)}) p(\vtheta^{(i+1)}),
\ee
where $p(\vtheta^{(i)} \to \vtheta^{(i+1}))$ depends only on $\vtheta^{(i)}$ and $\vtheta^{(i+1)}$. 
An additional requirement for an MCMC arises from the fact that the desired distribution is the equilibrium distribution.  In other words, if we assume that state $(i)$ of the chain is sampled from the desired PDF, $p(\vtheta^{(i)})=p(\vtheta|d,M)$ , then the next state $(i+1)$ must be sampled from the PDF as well, so that $p(\vtheta^{(i+1)})=p(\vtheta|d,M)$.  

One way to produce such a sequence of samples is via the Metropolis-Hastings algorithm, first proposed by Metropolis et al.~in 1953 \cite{Metropolis:1953}, and later generalized by Hastings:
\begin{enumerate}
  \item Given a current state $\vtheta^(i)$, propose the next state $\vtheta^p$ by drawing from a jump proposal distribution with probability $Q(\vtheta^(i) \to \vtheta^p)$.  
  \item Compute the probability of accepting the proposed jump as
\be
p_{\textnormal{accept}}  \equiv \min\Bigl(1,  frac{p(\vtheta^p|d)}{p(\vtheta^{(i)}|d)} \frac{Q(\vtheta^p \to
        \vtheta^{(i)})}{Q(\vtheta^{(i)} \to \vtheta^p)} \Bigr).
\ee
\item Pick a uniform random number $\alpha \in [0,1]$.  If $\alpha<  p_{\textnormal{accept}}$, accept the proposed jump, setting $\vtheta^{(i+1)}=\vtheta^p$.  Otherwise, reject the jump, and remain at the same location in parameter space for the next step, $\vtheta^{(i+1})=\vtheta^{(i)}$.
 \end{enumerate}
 
This jump proposal distribution $Q(\vtheta^{(i)} \to \vtheta^p)$ can depend on the parameters of the current state $\vtheta^{(i)}$, but not on the past history.  It must also allow any state within the allowed prior volume to be reachable by the MCMC.  Beyond these conditions, there is obviously a great deal of freedom in choosing the jump proposal distribution.  This is the most important choice in the MCMC, as it determines the sampling efficiency of the algorithm, i.e., the necessary length of the chain before it converges to the posterior PDF.  Creating an efficient jump proposal distribution requires an understanding of the structure of the parameter space which may not be available until the PDFs are found, creating a Catch-22; one possibility for resolving this infinite loop is described in Section \ref{sec:examples}.

It should be noted that although an MCMC who jump acceptance criterium obeys detailed balance (as the Metropolis-Hastings algorithm does) must eventually converge to the desired distribution, there is no way to guarantee convergence in a fixed number of steps or to test whether a chain has converged in a foolproof manner.  For example, MCMC chains can get stuck on local maxima, and if the autocorrelation length of the chain represents a substantial fraction of the total number of samples, the effective sample size may be too small to accurately represent the relative sizes of the modes in the PDF (however, see Section \ref{sec:examples} for one intriguing suggestion for remedying this issue).   

Finally, we note that, in practice, the randomly chosen initial starting point of the MCMC may be in a particularly unlikely location in the parameter space.  Because jumps are frequently local, we will generally want to ignore the first few autocorrelation lengths worth of points in a finite-size chain to avoid biases in the recovered posterior PDF due to the choice of the initial location.  The points thus discarded are referred to as "burn-in" points.

\subsection{RJMCMC}

The samples produced during by an MCMC algorithm can be used to directly perform a Monte Carlo evidence integral.  This results in a harmonic mean estimator for the evidence, which suffers from a large variance and a possible bias.  Additional techniques for the direct integration of evidence are described in \cite{Weinberg}, but also suffer from a variety of shortcomings.  \ilya{Will, please expand/modify this appropriately.}  An alternative approach to model selection among a set of models is based on performing an MCMC in a ``super-model'' that encompasses all of the models under consideration; this is known the the Reversible Jump Markov chain Monte Carlo (MCMC).

The parameter space of the super-model in an RJMCMC consists of a discrete parameter that identifies the model, $M_i$, and a set of continuous parameters appropriate for that model, $\vtheta_i$.  Thus, each sample consists of a model identifier and a location within the parameter space of that model, $\{M_i, \vtheta_i\}$.  We perform the MCMC in the ``super-model'' parameter space just like a regular MCMC; in general, we can both propose jumps to different parameters within a model (intramodel jumps) and jumps to a different model with different parameters (intermodel jumps).  The resulting chain samples from the posterior $p(M_i,\vtheta_i|d)$.  As in a usual MCMC, the PDF on the model as a parameter, with other parameters ignored, is obtained by trivially marginalizing over the remaining parameters, i.e., the evidence for a given model is just
\be
    p(M_i|d) = \int d\vtheta_i p(M_i, \vtheta_i|d) \approx \frac{N_i}{N},
 \ee
 where $N_i$ is the number of RJMCMC samples listing the $i$'th model and $N$ is the total chain length.  Thus, the probability of a particular model relative to other models under consideration is given by the fraction of RJMCMC samples lying in the parameter space of that model.
 
The main difficulty of achieving an efficient RJMCMC is finding a good jump proposal distribution for intermodel jumps.  In order to have relatively high acceptance ratios for intermodel jumps, which is necessary for efficient mixing between models, jumps should be preferentially proposed into regions with a high posterior.  However, because the algorithm is Markovian, it has no past memory, so a jump proposed into a model from outside it can not access information from earlier in the chain which may identify a posterior peak.  

The most promising solution to this problem is to identify a good jump proposal distribution in advance, by exploiting information from single-model MCMCs to generate efficient jump proposal distributions for our reversible jump MCMC.  (Single-model MCMCs can take small local jumps within their model, meaning that they are much less likely than an RJMCMC to lose a high-posterior mode once it has been located.)  The ideal jump proposal distribution for the parameters within a model would consist of the posterior PDF for those parameters, $p(\vtheta_i|M_i,d)$, and single-model MCMCs already represent samples from these posterior PDFs.  However, they are discrete, and so must be interpolated so that any location in the ``super-model'' parameter space can be reached.  The novel strategy we propose for efficiently interpolating a discretely sampled PDF is described in the next section.

\section{kD Trees and Interpolation}

\ilya{Mention example of bricks from \cite{Littenberg2009}.}

\section{RJMCMC Efficiency}

\section{Examples and other uses} \label{sec:examples}

BH mass paper [still not sure how to present this without repetition...  ]  

GW parameter estimation

The efficient interpolation of a PDF via a kD-tree described in this paper can be extremely useful in other contexts, beyond a reversible-jump MCMC.  We suggest two examples below: generating efficient jump proposal distributions and convergence tests?

\ilya{Mention nested sampling?}

\section{Conclusion/Discussion}





\nocite{Littenberg2009}

\bibliography{paper}

\end{document}